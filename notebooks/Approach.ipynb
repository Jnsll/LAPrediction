{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e84624-6673-4785-be9f-b90538f9a7b1",
   "metadata": {},
   "source": [
    "# Approach : Context-Aware Approximate Scientific Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb5705-0ce9-4a4a-b42c-b9f1af8b3b5b",
   "metadata": {},
   "source": [
    "## Description / Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7366d-d931-4af9-8d27-e3d67a8a90c9",
   "metadata": {},
   "source": [
    "Goal: Tailoring simulation model to a context of usage through an execution budget, by automatically and systematically applying approximate computing thanks to predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca009-1f6a-4960-a246-5cc0c389b6be",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e123068-f822-4232-97d8-49b70f6480be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb0981c-6908-47d5-b037-094d44b047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b7d7e5-6316-4c45-903c-2d67e7916f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aa398-f205-4a3a-9730-5266157f4a68",
   "metadata": {},
   "source": [
    "## Functions to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956a5a30-3932-421f-bcb3-cb7f45a92b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_time_prediction(budget, ratio_train):\n",
    "    # Retrieve data\n",
    "    df_data = pd.read_csv(os.path.join(path, \"data/\", \"Input_Data_Time_ValidMetric_Features_Rates_\" + str(nb_rates) + \"_Features_\" + \"Geomorph_CVHV_Saturation_Cells\" + \"_\" + str(scale) + \"_Comparable.csv\"), sep=\";\")\n",
    "    sites_completes = df_data.SiteNumber.unique()\n",
    "    # Split geographical sites into training and testing cases\n",
    "    training_cases, testing_cases = split_training_testing_cases(sites_completes, ratio_train)\n",
    "    # Extracting training and testing datasets\n",
    "    X_test, y_test_pred, y_test, data_test = get_time_prediction(df_data, training_cases, testing_cases)\n",
    "    \n",
    "    true_positive_time, true_negative_time, false_positive_time, false_negative_time, idxs = get_evaluation_from_time_prediction(y_test_pred, y_test, X_test, data_test)\n",
    "\n",
    "\n",
    "    return df_data, training_cases, testing_cases, idxs, true_positive_time, true_negative_time, false_positive_time, false_negative_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29db8549-0798-435e-91bf-b3c02370c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_testing_cases(sites_completes, ratio_train):\n",
    "    #Computing the number of sites that are used for the training\n",
    "    training_nb_cases = round(len(sites_completes) * ratio_train)\n",
    "\n",
    "    # Selecting the sites for the training and testing sets randomly \n",
    "    training_cases = random.sample(sites_completes.tolist(), training_nb_cases)\n",
    "    testing_cases = [x for x in sites_completes.tolist() if x not in training_cases]\n",
    "    \n",
    "    return training_cases, testing_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c5b176-21ca-4ff8-8df7-6f645083774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_prediction(df_data, training_cases, testing_cases):\n",
    "    data_train, data_test = retrieve_list_cases_and_split_data_BVE(df_data, training_cases, testing_cases)\n",
    "    X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets_BVE(data_train, data_test, features)\n",
    "    forest = train_forest(X_train, y_train)\n",
    "    y_test_pred = forest.predict(X_test)\n",
    "    #mse, r2, rmse = compute_standard_metrics(y_test, y_test_pred)\n",
    "    #print(\"MSE: \", mse)\n",
    "    #print(\"RMSE: \", rmse)\n",
    "    #print(\"R2: \", r2)\n",
    "    data_test = update_and_store_data_with_time_pred(path, data_test, y_test, y_test_pred, testing_cases)\n",
    "    return X_test, y_test_pred, y_test, data_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe121f3-67c9-4041-bcde-92d99f3c652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list_cases_and_split_data_BVE(df_data, training_cases, testing_cases):\n",
    "    \n",
    "    # Retrieving the dataset for the training phase\n",
    "    data_train = extract_data_from_list_of_sites(df_data, training_cases)\n",
    "    \n",
    "    # Retrieving the dataset for the testing phase\n",
    "    data_test = extract_data_from_list_of_sites(df_data, testing_cases)\n",
    "\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d087246-cfc8-451a-9d1a-20e2a15a2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_list_of_sites(data_complete, cases):\n",
    "    data_cases = pd.DataFrame(columns=data_complete.columns)\n",
    "    for case in cases:\n",
    "        data_case = data_complete.loc[(data_complete['SiteNumber'] == case)]\n",
    "        data_cases = pd.concat([data_cases, data_case], sort=False)\n",
    "        \n",
    "    return data_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b639882-7daa-445a-958d-59f53f79ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_outputs_datasets_BVE(data_train, data_test, features):\n",
    "    # load names of all the features contained in the dataset to extract the data we want from\n",
    "    global all_features\n",
    "    \n",
    "    y_train = data_train.filter([\"SiteNumber\", \"Time\"], axis=1)\n",
    "    X_train = data_train.drop([\"Chronicle\", \"Validation Metric\", \"Accuracy\", \"Time\"], axis=1)\n",
    "    del y_train[\"SiteNumber\"]\n",
    "    del X_train[\"SiteNumber\"]\n",
    "    \n",
    "    y_test = data_test.filter([\"SiteNumber\", \"Time\"], axis=1)\n",
    "    X_test = data_test.drop([\"Chronicle\", \"Validation Metric\", \"Accuracy\", \"Time\"], axis=1)\n",
    "    del y_test[\"SiteNumber\"]\n",
    "    del X_test[\"SiteNumber\"]\n",
    "    \n",
    "    \n",
    "    features_to_remove = [feature for feature in all_features if feature not in features]\n",
    "    for feature in features_to_remove:\n",
    "        del X_train[str(feature)]\n",
    "        del X_test[str(feature)]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b9ea30-e174-4e56-9e08-d591f5c889dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(X_train, y_train):\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=1000, criterion='squared_error', random_state=1, n_jobs=-1, oob_score = True, bootstrap = True\n",
    "    )\n",
    "    forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f27bcaf-751c-4ca1-85e3-08e163095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_metrics(y_test, y_test_pred):\n",
    "\n",
    "    mse = mean_squared_error(y_test.values.ravel(), y_test_pred)\n",
    "    r2 = r2_score(y_test.values.ravel(), y_test_pred)\n",
    "    rmse = metrics.mean_squared_error(y_test.values.ravel(), y_test_pred, squared=False)\n",
    "\n",
    "    return mse, r2, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d66e418f-3443-4c44-855d-23b845848fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_store_data_with_time_pred(path, data_test, y_test, y_test_pred, testing_cases):\n",
    "    suffixe = \"_\".join(map(str,list(map(int, sorted(testing_cases)))))\n",
    "    # If we want the testing dataset to correspond to one unique site instead of a ratio (e.g., 20%)\n",
    "    data_test = data_test.assign(Timetest=y_test.values.ravel())\n",
    "    data_test = data_test.assign(TimePred=y_test_pred)\n",
    "    \n",
    "    data_test.to_csv(os.path.join(path,\"data/Output_Data/Data_Test_With_Time_pred_Rates_\" + str(nb_rates) + \"_Features_\" + str('_'.join(features)) + \"_\" + str(scale)  + \"_\" + str(suffixe) + \".csv\"), index=False, sep=\";\")\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefb707f-4c70-47fe-a169-149966713760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_from_time_prediction(y_test_pred, y_test, X_test, data_test):\n",
    "    chuncks_pred = list()\n",
    "    true_positive_time = 0\n",
    "    true_negative_time = 0\n",
    "    false_positive_time = 0\n",
    "    false_negative_time = 0\n",
    "\n",
    "    for i in range(0, len(y_test_pred), 30):\n",
    "        chuncks_pred.append(y_test_pred[i:i+30])\n",
    "    idxs = list()\n",
    "    site = 0\n",
    "    for site_data in chuncks_pred:\n",
    "        first_time_under_budget = 0\n",
    "        item_site = 0\n",
    "        site += 1\n",
    "        for pred_time in site_data:\n",
    "            item_site +=1\n",
    "            if pred_time < budget:\n",
    "                first_time_under_budget +=1\n",
    "                if first_time_under_budget == 2:\n",
    "                    index_for_site = item_site-1\n",
    "                    \n",
    "                    idxs.append(((site-1)*30)+ index_for_site)\n",
    "                    pred_time_approach = round(pred_time)\n",
    "\n",
    "                    pred_rate = int(X_test.iloc[[((site-1)*30)+ index_for_site]][\"Rate\"])\n",
    "                    real_time_approach = int(y_test.iloc[[((site-1)*30)+ index_for_site]][\"Time\"])\n",
    "                    \n",
    "                    # In reality, is the simulation of this approximation rate respecting the budget\n",
    "                    prediction_time_evaluation = get_evaluation_with_time_prediction_under_budget(budget, real_time_approach)\n",
    "                    \n",
    "                    if prediction_time_evaluation:\n",
    "                        true_positive_time += 1\n",
    "                        print(\"TP p\")\n",
    "                    else:\n",
    "                        false_positive_time += 1\n",
    "                        print(\"FP p\")\n",
    "                    break\n",
    "                    \n",
    "        if item_site == 30 :\n",
    "            idxs.append(-9)\n",
    "            index_debut = (site - 1) * 30\n",
    "            for i in range(index_debut, index_debut + 30):\n",
    "                real_time_approach = int(data_test.iloc[[i]][\"Time\"])\n",
    "                if real_time_approach < budget:\n",
    "                    false_negative_time += 1\n",
    "                    print(\"FN p\")\n",
    "                    break\n",
    "                if i == index_debut + 30 - 1:\n",
    "                    true_negative_time += 1\n",
    "                    print(\"TN p\")\n",
    "\n",
    "            \n",
    "    \n",
    "    return true_positive_time, true_negative_time, false_positive_time, false_negative_time, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a722c813-d57a-413e-b647-a264ea5ca131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_with_time_prediction_under_budget(budget, real_time_approach):\n",
    "    # In reality, is the simulation of this approximation rate respecting the budget\n",
    "    if real_time_approach < budget:\n",
    "        prediction_time_evaluation = 1\n",
    "    else:\n",
    "        prediction_time_evaluation = 0\n",
    "        \n",
    "    return prediction_time_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17e160-dc7c-4238-9838-9e76354ceb94",
   "metadata": {},
   "source": [
    "## Pipeline for validity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284b63f2-fa8c-45a4-8781-34390edb815f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def pipeline_prediction_validation(df_data, training_cases, testing_cases, idxs, features_validity):   \n",
    "    y_test_pred_valid, y_test_valid = get_validity_prediction(df_data, training_cases, testing_cases, features_validity)\n",
    "    predicted_and_real_validity_values = get_validity_prediction_values_for_corresponding_approximation_rates(y_test_pred_valid, y_test_valid, idxs)\n",
    "    true_positive_valid = 0\n",
    "    true_negative_valid = 0\n",
    "    false_positive_valid = 0\n",
    "    false_negative_valid = 0\n",
    "\n",
    "    for predicted_validity in predicted_and_real_validity_values:\n",
    "        predicted_validity_value = predicted_validity[0]\n",
    "        real_validity_value = predicted_validity[1]\n",
    "        if predicted_validity_value == real_validity_value:\n",
    "            if predicted_validity_value:\n",
    "                true_positive_valid +=1\n",
    "                print(\"TP validity\")\n",
    "            else:\n",
    "                true_negative_valid += 1\n",
    "                print(\"TN validity\")\n",
    "        else:\n",
    "            if predicted_validity_value:\n",
    "                false_positive_valid +=1\n",
    "                print(\"FP validity \")\n",
    "            else:\n",
    "                false_negative_valid += 1\n",
    "                print(\"FN validity\")\n",
    "\n",
    "    return true_positive_valid, true_negative_valid, false_positive_valid, false_negative_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6fff12b-3292-4515-a2d8-f5c0ced51c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validity_prediction(df_data, training_cases, testing_cases, features_validity):\n",
    "    global k\n",
    "    df_data[\"Validity\"] = np.where(df_data[\"Validation Metric\"] > validity_threshold, 0, 1)\n",
    "    data_train_validity, data_test_validity = retrieve_list_cases_and_split_data_BVE(df_data, training_cases, testing_cases)\n",
    "    X_train_validity, y_train_validity, X_test_validity, y_test_validity = extract_features_and_outputs_datasets_BVE_validity(data_train_validity, data_test_validity, features_validity)\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train_validity, y_train_validity.values.ravel().astype(int))\n",
    "    y_test_pred_validity = classifier.predict(X_test_validity)\n",
    "    #acc_score = compute_score(y_test_validity, y_test_pred_validity)\n",
    "    #print(\"Validity Accuracy Score:\", acc_score)\n",
    "    \n",
    "    return y_test_pred_validity, y_test_validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103a2141-4001-425b-89a9-10f822c7a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_outputs_datasets_BVE_validity(data_train, data_test, features):\n",
    "    # load names of all the features contained in the dataset to extract the data we want from\n",
    "    global all_features\n",
    "    \n",
    "    X_train, y_train = create_input_and_output_datasets_for_validity(data_train)\n",
    "    X_test, y_test = create_input_and_output_datasets_for_validity(data_test)\n",
    "    \n",
    "    \n",
    "    features_to_remove = [feature for feature in all_features if feature not in features]\n",
    "    for feature in features_to_remove:\n",
    "        del X_train[str(feature)]\n",
    "        del X_test[str(feature)]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f7045e-9399-470a-bbe6-c5e1e586808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_datasets_for_validity(data):\n",
    "    y_data = data.filter([\"SiteNumber\", \"Validity\"], axis=1)\n",
    "    X_data = data.drop([\"Chronicle\", \"Validation Metric\", \"Accuracy\", \"Time\", \"Validity\"], axis=1)\n",
    "    del y_data[\"SiteNumber\"]\n",
    "    del X_data[\"SiteNumber\"]\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1449edc-6eb5-4c8c-bd95-b5aed0bf771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(y_test, y_test_pred):\n",
    "    acc_score = metrics.accuracy_score(y_test.values.ravel().astype(int), y_test_pred)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a45f092-9587-4bdc-aa89-5e2eff1c36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validity_prediction_values_for_corresponding_approximation_rates(y_test_pred_valid, y_test_real_valid, idxs):\n",
    "    chuncks_pred_valid = list()\n",
    "    predicted_and_real_validity_values = list()\n",
    "\n",
    "    for i in range(0, len(y_test_pred_valid), 30):\n",
    "        chuncks_pred_valid.append(y_test_pred_valid[i:i+30])\n",
    "\n",
    "    site = 0\n",
    "    for value_sites in chuncks_pred_valid:\n",
    "        # Checking if the prediction for the approximation rate led to no simulation under the execution budget\n",
    "        if idxs[site] == -9: \n",
    "            predicted_and_real_validity_values.append([1, 1])\n",
    "        else:\n",
    "            valid_pred = y_test_pred_valid[idxs[site]]\n",
    "            valid_real = int(y_test_real_valid.iloc[[idxs[site]]][\"Validity\"])\n",
    "        \n",
    "            predicted_and_real_validity_values.append([valid_pred, valid_real])\n",
    "        site+=1\n",
    "    \n",
    "    return predicted_and_real_validity_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d427d-59a8-426b-843a-d89d6aa0da62",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e9babf-7b70-4524-ae04-5e6e9c803b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(os.path.join(os.path.abspath(\"\"), os.pardir))\n",
    "nb_rates = 30\n",
    "chronicle = 0\n",
    "scale = \"BVE\"\n",
    "\n",
    "# Different sets of features \n",
    "set_geomorph = [\"Slope\", \"Elevation\", \"LC\", \"CW\", \"Area\"]\n",
    "set_CVHV = [\"Coastal Vulnerability\", \"Hydrological Vulnerability\"]\n",
    "set_saturation= [\"Satured Zone Area\", \"Vulnerability Sum\", \"Vulnerability Rate\"]\n",
    "set_cells = [\"Number of Cells\"]\n",
    "all_features = set_geomorph + set_CVHV + set_saturation + set_cells\n",
    "\n",
    "# We select the type of features we want to use for training our model\n",
    "features = set_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005db91-17e5-4802-9e30-449f8bd30ada",
   "metadata": {},
   "source": [
    "## Replications x 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa70d342-16cb-4cc6-89b3-29666dc985bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Replication 1\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "FN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 2\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "FP p\n",
      "FP validity \n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 3\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 4\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "FN validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 5\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "FN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 6\n",
      "----\n",
      "Budget: 300\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 7\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "FP validity \n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 8\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "FP validity \n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 9\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 10\n",
      "----\n",
      "Budget: 300\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 11\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 12\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 13\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 14\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 15\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 16\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 17\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 18\n",
      "----\n",
      "Budget: 300\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 19\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 20\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 21\n",
      "----\n",
      "Budget: 300\n",
      "TN p\n",
      "TP validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 22\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 23\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "FP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 24\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "FP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n",
      "Replication 25\n",
      "----\n",
      "Budget: 300\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 600\n",
      "TP p\n",
      "TN validity\n",
      "----\n",
      "Budget: 1800\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 3600\n",
      "TP p\n",
      "TP validity\n",
      "----\n",
      "Budget: 18000\n",
      "TP p\n",
      "TP validity\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "validity_threshold = 0.1\n",
    "k=3\n",
    "features_valid = set_geomorph\n",
    "budgets = [300, 600, 1800, 3600, 18000]\n",
    "ratio_train = 0.95\n",
    "\n",
    "true_positive_times = 0\n",
    "true_negative_times = 0\n",
    "false_positive_times = 0\n",
    "false_negative_times = 0\n",
    "true_positive_valids = 0\n",
    "true_negative_valids = 0\n",
    "false_positive_valids = 0\n",
    "false_negative_valids = 0\n",
    "true_positive_approach = 0\n",
    "true_negative_approach = 0\n",
    "false_positive_approach = 0\n",
    "false_negative_approach = 0\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    print(\"------------\")\n",
    "    print(\"Replication\", i+1)\n",
    "    correct_approach_replication = 0\n",
    "    for budget in budgets:\n",
    "        print('----')\n",
    "        print(\"Budget:\", budget)\n",
    "        df_data, training_cases, testing_cases, idxs, true_positive_time, true_negative_time, false_positive_time, false_negative_time = pipeline_time_prediction(budget, ratio_train)\n",
    "        true_positive_valid, true_negative_valid, false_positive_valid, false_negative_valid = pipeline_prediction_validation(df_data, training_cases, testing_cases, idxs,features_valid)\n",
    "                \n",
    "        true_positive_times += true_positive_time\n",
    "        true_negative_times += true_negative_time\n",
    "        false_positive_times += false_positive_time\n",
    "        false_negative_times += false_negative_time\n",
    "        true_positive_valids += true_positive_valid\n",
    "        true_negative_valids += true_negative_valid\n",
    "        false_positive_valids += false_positive_valid\n",
    "        false_negative_valids += false_negative_valid\n",
    "\n",
    "        if true_positive_time and true_positive_valid:\n",
    "            true_positive_approach += 1\n",
    "        elif (false_positive_time and true_positive_valid) or (false_positive_time and false_positive_valid) or (true_positive_time and false_positive_valid):\n",
    "            false_positive_approach += 1\n",
    "        elif (true_positive_time and false_negative_valid) or (false_negative_time and true_positive_valid):\n",
    "            false_negative_approach += 1\n",
    "        else:\n",
    "            true_negative_approach += 1\n",
    "\n",
    "print(\"------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e9756-04d2-44ad-a161-eed20b495507",
   "metadata": {},
   "source": [
    "# Accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50457888-9f90-4a21-8f11-fd04d00503ca",
   "metadata": {},
   "source": [
    "## Approximation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b28c69fd-de91-437c-989e-3afb88f8a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824\n"
     ]
    }
   ],
   "source": [
    "Accuracy_p = 0\n",
    "\n",
    "true_prediction_times = true_positive_times + true_negative_times\n",
    "number_of_prediction_times = true_prediction_times + false_positive_times + false_negative_times\n",
    "\n",
    "Accuracy_times = float(true_prediction_times) / float(number_of_prediction_times)\n",
    "print(Accuracy_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b4b93-a607-43d9-9454-a24b0ca493d5",
   "metadata": {},
   "source": [
    "## Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae831803-88b5-49ca-9433-3c1451dbabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n"
     ]
    }
   ],
   "source": [
    "Accuracy_validity = 0\n",
    "\n",
    "true_prediction_valids = true_positive_valids + true_negative_valids\n",
    "number_of_prediction_valids = true_prediction_valids + false_positive_valids + false_negative_valids\n",
    "\n",
    "Accuracy_valids = float(true_prediction_valids) / float(number_of_prediction_valids)\n",
    "print(Accuracy_valids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77766d51-b0e9-48c3-8f05-f1f358310126",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4b6223a-bee3-4bfa-866c-6ed1209c98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872\n"
     ]
    }
   ],
   "source": [
    "Accuracy_approach =0\n",
    "\n",
    "true_prediction_approach = true_positive_approach + true_negative_approach\n",
    "number_of_prediction_approach = true_prediction_approach + false_positive_approach + false_negative_approach\n",
    "\n",
    "Accuracy_approach = float(true_prediction_approach) / float(number_of_prediction_approach)\n",
    "print(Accuracy_approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48664280-ce19-4f70-ab0c-7633d39abb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
