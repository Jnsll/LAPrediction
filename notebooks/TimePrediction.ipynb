{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e84624-6673-4785-be9f-b90538f9a7b1",
   "metadata": {},
   "source": [
    "# Time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb5705-0ce9-4a4a-b42c-b9f1af8b3b5b",
   "metadata": {},
   "source": [
    "## Description / Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7366d-d931-4af9-8d27-e3d67a8a90c9",
   "metadata": {},
   "source": [
    "Goal: Create data model to predict properties (e.g., execution time, validity metric) of a simulation thanks to features regarding that simulation. The end goal is to define the approximation factor tu use for that simulation to match a defined execution budget (e.g., execution time).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac22a9c-a3cc-4a79-81a1-6ccd350980d1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b7d7e5-6316-4c45-903c-2d67e7916f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aa398-f205-4a3a-9730-5266157f4a68",
   "metadata": {},
   "source": [
    "## Functions to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ac280c-dfcc-44f2-b724-007d51da6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list_cases_and_split_data_BVE(data_complete, sites_completes, ratio_train):\n",
    "    #Computing the number of sites that are used for the training\n",
    "    training_nb_cases = round(len(sites_completes) * ratio_train)\n",
    "\n",
    "    # Selecting the sites for the training and testing sets randomly \n",
    "    training_cases = random.sample(sites_completes.tolist(), training_nb_cases)\n",
    "    testing_cases = [x for x in sites_completes.tolist() if x not in training_cases]\n",
    "    \n",
    "    # Retrieving the dataset for the training phase\n",
    "    data_train = pd.DataFrame(columns=data_complete.columns)\n",
    "    for cas in training_cases:\n",
    "        train = data_complete.loc[(data_complete['SiteNumber'] == cas)]\n",
    "        data_train = pd.concat([data_train, train], sort=False)\n",
    "    # Retrieving the dataset for the testing phase\n",
    "    data_test = pd.DataFrame(columns=data_complete.columns)\n",
    "    for case in testing_cases:\n",
    "        test = data_complete.loc[(data_complete['SiteNumber'] == case)]\n",
    "        data_test = pd.concat([data_test, test], sort=False)\n",
    "\n",
    "    return data_train, data_test, training_cases, testing_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b639882-7daa-445a-958d-59f53f79ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_outputs_datasets_BVE(data_train, data_test, features):\n",
    "    # load names of all the features contained in the dataset to extract the data we want from\n",
    "    global all_features\n",
    "    \n",
    "    y_train = data_train.filter([\"SiteNumber\", \"Time\"], axis=1)\n",
    "    X_train = data_train.drop([\"Chronicle\", \"Validation Metric\", \"Accuracy\", \"Time\"], axis=1)\n",
    "    del y_train[\"SiteNumber\"]\n",
    "    del X_train[\"SiteNumber\"]\n",
    "    \n",
    "    y_test = data_test.filter([\"SiteNumber\", \"Time\"], axis=1)\n",
    "    X_test = data_test.drop([\"Chronicle\", \"Validation Metric\", \"Accuracy\", \"Time\"], axis=1)\n",
    "    del y_test[\"SiteNumber\"]\n",
    "    del X_test[\"SiteNumber\"]\n",
    "    \n",
    "    \n",
    "    features_to_remove = [feature for feature in all_features if feature not in features]\n",
    "    for feature in features_to_remove:\n",
    "        del X_train[str(feature)]\n",
    "        del X_test[str(feature)]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51b9ea30-e174-4e56-9e08-d591f5c889dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(X_train, y_train):\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=1000, criterion='squared_error', random_state=1, n_jobs=-1, oob_score = True, bootstrap = True\n",
    "    )\n",
    "    forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f27bcaf-751c-4ca1-85e3-08e163095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_metrics(y_test, y_test_pred):\n",
    "\n",
    "    mse = mean_squared_error(y_test.values.ravel(), y_test_pred)\n",
    "    r2 = r2_score(y_test.values.ravel(), y_test_pred)\n",
    "\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d66e418f-3443-4c44-855d-23b845848fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_store_data_with_time_pred(path, data_test, y_test, y_test_pred, testing_cases, one_case=False):\n",
    "    suffixe = \"_\".join(map(str,list(map(int, sorted(testing_cases)))))\n",
    "    # If we want the testing dataset to correspond to one unique site instead of a ratio (e.g., 20%)\n",
    "    if one_case:\n",
    "        suffixe += \"_OneCase\"\n",
    "    data_test = data_test.assign(Timetest=y_test.values.ravel())\n",
    "    data_test = data_test.assign(TimePred=y_test_pred)\n",
    "    \n",
    "    data_test.to_csv(os.path.join(path,\"data/Output_Data/Data_Test_With_Time_pred_Rates_\" + str(nb_rates) + \"_Features_\" + str('_'.join(features)) + \"_\" + str(scale)  + \"_\" + str(suffixe) + \".csv\"), index=False, sep=\";\")\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6dc23f-79f1-4a8b-a23f-975f2ca8daf3",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ba8e4d0-9cbd-4b8a-8999-cd954a274a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/june/Dev/LAPrediction\n",
      "['Number of Cells']\n"
     ]
    }
   ],
   "source": [
    "#path = \"/Users/june/Dev/LAPrediction/\"\n",
    "path = os.path.abspath(os.path.join(os.path.abspath(\"\"), os.pardir))\n",
    "print(path)\n",
    "nb_rates = 30\n",
    "chronicle = 0\n",
    "#features = \"Geomorph_CVHV_Saturation_Cells\"\n",
    "scale = \"BVE\"\n",
    "ratio_train = 0.8\n",
    "\n",
    "# Different sets of features \n",
    "set_geomorph = [\"Slope\", \"Elevation\", \"LC\", \"CW\", \"Area\"]\n",
    "set_CVHV = [\"Coastal Vulnerability\", \"Hydrological Vulnerability\"]\n",
    "set_saturation= [\"Satured Zone Area\", \"Vulnerability Sum\", \"Vulnerability Rate\"]\n",
    "set_cells = [\"Number of Cells\"]\n",
    "all_features = set_geomorph + set_CVHV + set_saturation + set_cells\n",
    "\n",
    "# We select the type of features we want to use for training our model\n",
    "features = set_cells\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca009-1f6a-4960-a246-5cc0c389b6be",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23f13450-9800-4d6d-9f0c-9f31a290c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_pred_time(path, nb_rates, features, scale, ratio_train):\n",
    "    df_data = pd.read_csv(os.path.join(path, \"data/\", \"Input_Data_Time_ValidMetric_Features_Rates_\" + str(nb_rates) + \"_Features_\" + \"Geomorph_CVHV_Saturation_Cells\" + \"_\" + str(scale) + \"_Comparable.csv\"), sep=\";\")\n",
    "    #data_complete = extract_complete_data_for_BVE(df_data)\n",
    "    sites_completes = df_data.SiteNumber.unique()\n",
    "    data_train, data_test, training_cases, testing_cases = retrieve_list_cases_and_split_data_BVE(df_data, sites_completes, ratio_train)\n",
    "    X_train, y_train, X_test, y_test = extract_features_and_outputs_datasets_BVE(data_train, data_test, features)\n",
    "    forest = train_forest(X_train, y_train)\n",
    "    y_test_pred = forest.predict(X_test)\n",
    "    mse, r2 = compute_standard_metrics(y_test, y_test_pred)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"R2: \", r2)\n",
    "    data_test = update_and_store_data_with_time_pred(path, data_test, y_test, y_test_pred, testing_cases, one_case=False)\n",
    "    return mse, r2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02a28c2d-553b-4a95-99f6-5a274aa598dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  950185.5224610138\n",
      "R2:  0.9485038184126715\n",
      "MSE:  2132328.587199666\n",
      "R2:  0.9463765724938249\n",
      "MSE:  458149.17684877035\n",
      "R2:  0.9910560694498923\n",
      "MSE:  722627.0676465275\n",
      "R2:  0.9810094462932545\n",
      "MSE:  510244.4690254335\n",
      "R2:  0.9569621481251954\n",
      "MSE:  1999661.3422209334\n",
      "R2:  0.9400487946207016\n",
      "MSE:  637558.5071142132\n",
      "R2:  0.9828691453099762\n",
      "MSE:  2257499.110813523\n",
      "R2:  0.9363827905882856\n",
      "MSE:  563997.4232822\n",
      "R2:  0.8217189517166186\n",
      "MSE:  1529448.1337656127\n",
      "R2:  0.9703002896914849\n"
     ]
    }
   ],
   "source": [
    "scores_r2 = []\n",
    "for i in range(10):\n",
    "    _, r2 = pipeline_pred_time(path, nb_rates, features, scale, ratio_train)\n",
    "    scores_r2.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6235655f-ab09-4d80-8fd6-1df2d71c6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9485038184126715, 0.9463765724938249, 0.9910560694498923, 0.9810094462932545, 0.9569621481251954, 0.9400487946207016, 0.9828691453099762, 0.9363827905882856, 0.8217189517166186, 0.9703002896914849]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9475228026701905"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "print(scores_r2)\n",
    "statistics.mean(scores_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40b617-aeaf-4299-a735-49a1c2117f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
