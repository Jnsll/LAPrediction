{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the p-degree of aggregation for a new site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Goal: We want to predict the H indicator values according to the aggregation rate (p) for a new geographical site.*  \n",
    "The prediction is carried out considering only one chronicle and one approximation. The dataset contains the following data for each simulation configuration:\n",
    "- the site number\n",
    "- the H indicator values\n",
    "- the execution time\n",
    "- the number of lines in the input file\n",
    "- the vulnerability rate\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Link(source=(Text(value=''), 'value'), target=(IntSlider(value=1, min=1), 'value'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def on_value_change(change):\n",
    "    print(change['new'])\n",
    "\n",
    "slider = widgets.IntSlider(min=1, max=100, step=1, continuous_update=True)\n",
    "play = widgets.Text()\n",
    "\n",
    "slider.observe(on_value_change, 'value')\n",
    "widgets.jslink((play, 'value'), (slider, 'value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b13bfdeb5944438089aaaae7dc9117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb865f62c184f5eaac035b87930bc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(play.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8f24ddc3944677bda24bf3f55b0813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Site to predict:', index=9, options=(('Breville-Sur-Mer', 1), ('Jullouville', 4), ('Etré…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Lib imports\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "# Global variables\n",
    "result_folder = \"/run/media/jnsll/b0417344-c572-4bf5-ac10-c2021d205749/exps_modflops/results/\"\n",
    "dataset_filename = \"Exps_H_Indicator_All_Sites.csv\"\n",
    "\n",
    "# Prediction variables\n",
    "chronicle = 0\n",
    "approx = 0\n",
    "#test_site = 1 # belongs to [1,...]\n",
    "learn_size = 0.3\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "from IPython.display import Javascript, display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "liste_site = x=widgets.Dropdown(\n",
    "    options=[('Breville-Sur-Mer', 1), ('Jullouville', 4), ('Etréham', 5), ('Genêts', 6), ('Saint-Pair-sur-Mer', 7), ('Arromanches-les-Bains', 8), ('Courtils', 10), ('Lessay', 11), ('Doville', 12), ('Lestre', 17), ('Banville', 18), ('Isigny-sur-Mer', 19)],\n",
    "    value=17,\n",
    "    description='Site to predict:',\n",
    ")\n",
    "#output2 = widgets.Output()\n",
    "\n",
    "display(liste_site)\n",
    "\n",
    "def on_value_change(change):\n",
    "    #print(change['new'])\n",
    "    test_site = change['new']\n",
    "    print(test_site)\n",
    "\n",
    "\n",
    "\n",
    "liste_site.observe(on_value_change, names='value')\n",
    "\n",
    "#interact(f, x=widgets.Dropdown(\n",
    "#    options=[('Breville-Sur-Mer', 1), ('Jullouville', 4), ('Etréham', 5), ('Genêts', 6), ('Saint-Pair-sur-Mer', 7), ('Arromanches-les-Bains', 8), ('Courtils', 10), ('Lessay', 11), ('Doville', 12), ('Lestre', 17), ('Banville', 18), ('Isigny-sur-Mer', 19)],\n",
    "#    value=17,\n",
    "#    description='Site to predict:',\n",
    "#))\n",
    "\n",
    "\n",
    "#def set_site(site):\n",
    "#    pass\n",
    "\n",
    "#def run_all(ev):\n",
    "#    display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())'))\n",
    "\n",
    "#interact(set_site, site=widgets.Dropdown(\n",
    "#    options=[('Breville-Sur-Mer', 1), ('Jullouville', 4), ('Etréham', 5), ('Genêts', 6), ('Saint-Pair-sur-Mer', 7), ('Arromanches-les-Bains', 8), ('Courtils', 10), ('Lessay', 11), ('Doville', 12), ('Lestre', 17), ('Banville', 18), ('Isigny-sur-Mer', 19)],\n",
    "#    value=17,\n",
    "#    description='Site to predict:',\n",
    "#))  \n",
    "\n",
    "\n",
    "#test_site = site.value\n",
    "#print(site.value, test_site)\n",
    "    \n",
    "\n",
    "#button = widgets.Button(description=\"Predict\")\n",
    "#button.on_click(run_all)\n",
    "#display(button)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test site:  Output(outputs=({'output_type': 'stream', 'text': '4\\n4\\n', 'name': 'stdout'},))\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/run/media/jnsll/b0417344-c572-4bf5-ac10-c2021d205749'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2234fc707d1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mCHECK_FOLDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMYDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mCHECK_FOLDER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMYDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The directory did not exist. It has been created here: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMYDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/run/media/jnsll/b0417344-c572-4bf5-ac10-c2021d205749'"
     ]
    }
   ],
   "source": [
    "print(\"test site: \", test_site)\n",
    "\n",
    "# Path to store the files created during the prediction process\n",
    "MYDIR = result_folder + \"ZLearning/\" + \"Approx\"+ str(approx) + \"/Chronicle\" + str(chronicle) + \"/SiteTest\" + str(test_site)\n",
    "\n",
    "# Checking if the path and directory where to store the prediction files exists, if not it is created\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"The directory did not exist. It has been created here: \" + MYDIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and formatting the dataset for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lib imports\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset and storing it inside a dataframe\n",
    "df = pd.read_csv(result_folder + dataset_filename)\n",
    "\n",
    "# Only selecting the data corresponding to the chronicle and approximation chosen\n",
    "df_chr = df[df[\"Chronicle\"]==chronicle]\n",
    "df_Chr_Approx = df_chr[df_chr[\"Approx\"]==approx]\n",
    "\n",
    "# Removing the dataframe columns which are not to be used for the prediction\n",
    "del df_Chr_Approx[\"Approx\"]\n",
    "del df_Chr_Approx[\"Chronicle\"]\n",
    "del df_Chr_Approx[\"Execution Time\"]\n",
    "del df_Chr_Approx[\"Number of Lines\"]\n",
    "\n",
    "print(\"test site: \", test_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot of the variable to predict (H indicator value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lib imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables for the scatter plot\n",
    "## Names of the features corresponding to the names of the columns of the dataframe\n",
    "features = [\"Rate\", \"Satured Zone Area\", \"Vulnerability Sum\", \"Vulnerability Rate\", \"Global Area of site (in cells)\", \"Saturation Rate\"]\n",
    "## colors wanted to be used for the each plot for the corresponding feature\n",
    "colors = [\"black\", \"blue\", \"orange\", \"grey\", \"green\", \"purple\"]\n",
    "\n",
    "# Iterating over the feature\n",
    "for nb_feature in range(len(features)):\n",
    "    plt.scatter(df_Chr_Approx[features[nb_feature]], df_Chr_Approx['H Error'], color=colors[nb_feature])\n",
    "    plt.title('H Error Vs ' + features[nb_feature], fontsize=14)\n",
    "    plt.xlabel(features[nb_feature], fontsize=14)\n",
    "    plt.ylabel('H Error', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    \n",
    "\n",
    "    plt.savefig(MYDIR + '/simple_scatter_plot_HError_' + features[nb_feature] + '.png') #, bbox_inches='tight'\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics from the learning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lib imports\n",
    "import numpy as np\n",
    "\n",
    "# Variable to predict\n",
    "y = df_Chr_Approx.filter([\"Site_number\", \"H Error\"], axis=1)\n",
    "#y = pd.concat([df_Chr_Approx[\"Site_number\"], df_Chr_Approx[\"H Error\"]], axis=1)\n",
    "# Features used to predict\n",
    "X = df_Chr_Approx.drop('H Error', axis=1)\n",
    "#new = old.filter(['A','B','D'], axis=1)\n",
    "print(\"Learning Dataset has {} data points with {} variables each.\".format(*df_Chr_Approx.shape))\n",
    "\n",
    "\n",
    "# Minimum value of the data\n",
    "minimum_H = np.amin(y[\"H Error\"])\n",
    "# Maximum value of the data\n",
    "maximum_H = np.amax(y[\"H Error\"])\n",
    "\n",
    "# Mean value of the data\n",
    "mean_H = np.mean(y[\"H Error\"])\n",
    "\n",
    "# Median value of the data\n",
    "median_H = np.median(y[\"H Error\"])\n",
    "\n",
    "# Standard deviation of values of the data\n",
    "std_H = np.std(y[\"H Error\"])\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for dataset:\\n\")\n",
    "print(\"Minimum H: {}\".format(minimum_H)) \n",
    "print(\"Maximum H: {}\".format(maximum_H))\n",
    "print(\"Mean H: {}\".format(mean_H))\n",
    "print(\"Median H {}\".format(median_H))\n",
    "print(\"Standard deviation of H: {}\".format(std_H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplots of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_Chr_Approx, height=2.5)\n",
    "plt.savefig(MYDIR + '/Pairplots_HError' + '.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib imports\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "cm = np.corrcoef(df_Chr_Approx.values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cm,\n",
    "                cbar=True,\n",
    "                annot=True,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                annot_kws={'size': 10},\n",
    "                yticklabels=list(df_Chr_Approx),\n",
    "                xticklabels=list(df_Chr_Approx))\n",
    "plt.savefig(MYDIR + '/CorrelationMatrix_HError'+'.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the prediction model with the learning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting training data and tetsing data for the dataset used for to build the prediction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=learn_size, random_state=1)\n",
    "#print(\"Training and testing split was successful.\")\n",
    "\n",
    "# Splitting the y (H indicator) into training and testing data\n",
    "# Extracting the data corresponding to the site we want to predict\n",
    "y_test = y[y.Site_number == int(test_site)]\n",
    "## We do not want to take the site number into account for the prediction\n",
    "del y_test[\"Site_number\"] \n",
    "\n",
    "# Removing the data for the site we want to predict\n",
    "y_train = y.drop(y[y.Site_number == int(test_site)].index)\n",
    "## We do not want to take the site number into account for the prediction\n",
    "del y_train[\"Site_number\"]\n",
    "\n",
    "# Splitting the x (features) into training and testing data\n",
    "X_test = X[X.Site_number == int(test_site)]\n",
    "## We do not want to take the site number into account for the prediction\n",
    "del X_test[\"Site_number\"] \n",
    "\n",
    "# Removing the data for the site we want to predict\n",
    "X_train = X.drop(X[X.Site_number == int(test_site)].index)\n",
    "## We do not want to take the site number into account for the prediction\n",
    "del X_train[\"Site_number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a random Forest algo to build the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# n_estimators :\n",
    "# creiterion :\n",
    "# random_state :\n",
    "# n_jobs :\n",
    "forest = RandomForestRegressor(n_estimators=1000, criterion='mse', random_state=1, n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Predicting results\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "#print(y_test_pred, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the prediction quality results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train=mean_squared_error(y_train, y_train_pred)\n",
    "mse_test=mean_squared_error(y_test, y_test_pred)\n",
    "r2_train=r2_score(y_train, y_train_pred)\n",
    "r2_test=r2_score(y_test, y_test_pred)\n",
    "print('MSE train: %.3f, test: %.3f' % (mse_train, mse_test))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_train,r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with the test site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_Chr0_Approx0_Site17)\n",
    "def get_testSite_datasets(df_Chr_Approx_SiteTest):\n",
    "    y_testSite = df_Chr_Approx_SiteTest[\"H Error\"]   #df_Chr0_Approx0.filter([\"H Error\"], axis=1)\n",
    "\n",
    "    X_testSite = df_Chr_Approx_SiteTest.drop('H Error', axis=1)\n",
    "    \n",
    "    return X_testSite,y_testSite\n",
    "#print(X_testSite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_testSite(forest, X_testSite, y_testSite, y_train, y_train_pred):\n",
    "    y_testSite_test = forest.predict(X_testSite)\n",
    "    mse_testSite_train=mean_squared_error(y_train, y_train_pred)\n",
    "    mse_testSite_test=mean_squared_error(y_testSite, y_testSite_test)\n",
    "    r2_testSite_train=r2_score(y_train, y_train_pred)\n",
    "    r2_testSite_test=r2_score(y_testSite, y_testSite_test)\n",
    "    print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_testSite, y_testSite_test)))\n",
    "    print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),r2_score(y_testSite, y_testSite_test)))\n",
    "    return mse_testSite_train,mse_testSite_test,r2_testSite_train,r2_testSite_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
